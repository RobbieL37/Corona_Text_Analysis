{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93856f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "import plotly.express as px\n",
    "import scipy.stats\n",
    "import math\n",
    "import statistics\n",
    "import string \n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models\n",
    "from nltk.text import Text\n",
    "# ----------------------------------------\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "# ----------------------------------------\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c486db",
   "metadata": {},
   "source": [
    "### Import all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1bca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data importing \n",
    "lowes_6026 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_3286026.csv')\n",
    "lowes_0314 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_3380314.csv')\n",
    "lowes_0511 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_50280511.csv') \n",
    "lowes_6162 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_1003066162.csv')\n",
    "lowes_6209 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_5000026209.csv')\n",
    "lowes_9855 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\lowes.com_5001899855.csv')\n",
    "# data importing \n",
    "homedepot_4796 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\homedepot.com_204074796.csv')\n",
    "homedepot_7071 = pd.read_csv('C:\\\\Users\\\\lxf12\\\\Desktop\\\\Folder of folders\\\\Corona New project\\\\Lowes_Homedepot_Reviews\\\\homedepot.com_319247071.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f09485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxf12\\AppData\\Local\\Temp\\ipykernel_15484\\779606820.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "# set display option to max to see all information in review column\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad5190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowes_6026 has null rows amount: 30\n",
      "after cleaning, lowes_6026 has null rows amount: 0\n",
      "lowes_0314 has null rows amount: 10\n",
      "after cleaning, lowes_0314 has null rows amount: 0\n",
      "lowes_0511 has null rows amount: 15\n",
      "after cleaning, lowes_0511 has null rows amount: 0\n",
      "lowes_6162 has null rows amount: 297\n",
      "after cleaning, lowes_6162 has null rows amount: 0\n",
      "lowes_6209 has null rows amount: 76\n",
      "after cleaning, lowes_6209 has null rows amount: 0\n",
      "lowes_9855 has null rows amount: 170\n",
      "after cleaning, lowes_9855 has null rows amount: 0\n",
      "homedepot_4796 has null rows amount: 186\n",
      "after cleaning, homedepot_4796 has null rows amount: 0\n",
      "homedepot_7071 has null rows amount: 9\n",
      "after cleaning, homedepot_7071 has null rows amount: 0\n"
     ]
    }
   ],
   "source": [
    "# drop null value\n",
    "datalist = [lowes_6026, lowes_0314, lowes_0511, lowes_6162,\n",
    "                    lowes_6209, lowes_9855, \n",
    "                     homedepot_4796, homedepot_7071]\n",
    "namelist = ['lowes_6026', 'lowes_0314', 'lowes_0511', 'lowes_6162',\n",
    "                    'lowes_6209', 'lowes_9855', \n",
    "                     'homedepot_4796', 'homedepot_7071']\n",
    "n = 0 \n",
    "\n",
    "for i in datalist: \n",
    "    # drop rows with Not a Number (NaN) and None values\n",
    "    name = namelist[n]\n",
    "    n += 1\n",
    "    print(name + ' has null rows amount: '+ str(i['Review'].isna().sum()))\n",
    "    i.dropna(subset=['Review'], inplace=True)\n",
    "    print('after cleaning, ' + name + ' has null rows amount: ' \n",
    "          + str(i['Review'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff60ea91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lowes_0511.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10adf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# homedepot_7071.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce29bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: DataFrame\n",
      "Number of rows: 780\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 390\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 25\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 203\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 24\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 100\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 324\n",
      "DataFrame: DataFrame\n",
      "Number of rows: 51\n"
     ]
    }
   ],
   "source": [
    "datalist = [lowes_6026, lowes_0314, lowes_0511, lowes_6162,\n",
    "                    lowes_6209, lowes_9855, \n",
    "                     homedepot_4796, homedepot_7071]\n",
    "\n",
    "# Loop through the list and print the name and shape of each dataframe\n",
    "for i in datalist:\n",
    "    print(\"DataFrame:\", type(i).__name__)\n",
    "    print(\"Number of rows:\", i.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57dd075",
   "metadata": {},
   "source": [
    "### Combine the 8 data at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83da7b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1897 entries, 0 to 59\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Market_place  1897 non-null   object \n",
      " 1   URL           1897 non-null   object \n",
      " 2   Product_name  1897 non-null   object \n",
      " 3   SKU           1897 non-null   object \n",
      " 4   Price         1897 non-null   float64\n",
      " 5   Currency      1897 non-null   object \n",
      " 6   Subject       1834 non-null   object \n",
      " 7   Author        1855 non-null   object \n",
      " 8   Date          1897 non-null   object \n",
      " 9   Review        1897 non-null   object \n",
      " 10  Stars         1897 non-null   int64  \n",
      " 11  like          1522 non-null   float64\n",
      " 12  dislike       1522 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 207.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Combine the dataframes by rows\n",
    "datalist = [lowes_6026, lowes_0314, lowes_0511, lowes_6162,\n",
    "                    lowes_6209, lowes_9855, \n",
    "                     homedepot_4796, homedepot_7071]\n",
    "combined_df = pd.concat(datalist, axis=0)\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e71a970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combined_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a3afe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combined_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8182869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c05d39",
   "metadata": {},
   "source": [
    "### Separate Negative and Positive Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623e3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select negative(0) or positive ranking(1): 1\n"
     ]
    }
   ],
   "source": [
    "# 8 data x 2 categories \n",
    "try:\n",
    "    user_select = int(input(\"Please select negative(0) or positive ranking(1): \"))\n",
    "except: \n",
    "    print(\"Your input is not correct. Please input again according the tips.\")\n",
    "\n",
    "if user_select == 0:\n",
    "    # get reviews that have given 1, 2, and 3 stars (negative)\n",
    "    combined_df = combined_df.loc[combined_df['Stars'] <= 3]\n",
    "elif user_select == 1:\n",
    "    # get reviews that have given 4 and 5 stars (positive)\n",
    "    combined_df = combined_df.loc[combined_df['Stars'] > 3]\n",
    "else: \n",
    "    print(\"Your input is not correct. Please input again according the tips.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fcbce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0931c",
   "metadata": {},
   "source": [
    "### Extract the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5583060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it all string\n",
    "text_01 = combined_df['Review'].to_string(index=False)\n",
    "# text_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8849faa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4f7a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_02 = text_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc2e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all characters to lowercase\n",
    "text_02 = text_02.lower()\n",
    "# Create a translation table with all punctuation characters mapped to None\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "# remove punctuations using RegexpTokenizer\n",
    "text_02 = text_02.translate(translator)\n",
    "# Use regex to remove all numbers\n",
    "text_02 = re.sub(r'\\d+', '', text_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eed66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lxf12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # customize stop_words by including a custom list of words\n",
    "    custom_stop_words = ['toilet', 'rating', 'provided', 'verified', 'purchaser']\n",
    "#     Rating provided by a verified purchaser  \n",
    "# #     custom_stop_words = ['new','toilet', 'factory', 'flush', 'sku', 'photos', 'stay', \n",
    "# #                                      'lid', 'good', 'great', 'handle', 'top', 'high', 'urine']\n",
    "    stop_words.update(custom_stop_words)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa62289",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_02 = remove_stopwords(text_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba2752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations using RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "token = tokenizer.tokenize(text_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950907c5",
   "metadata": {},
   "source": [
    "### N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37861873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many words do you want to aggregate? (1-8)4\n"
     ]
    }
   ],
   "source": [
    "# N-gram generation\n",
    "N = int(input('How many words do you want to aggregate? (1-8)'))\n",
    "N_grams = list(ngrams(token, N))\n",
    "words = [' '.join(tr) for tr in N_grams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3765bf8",
   "metadata": {},
   "source": [
    "### Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4269ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('review', 'collected', 'part', 'promotion'), 16),\n",
       " (('uses', 'much', 'less', 'water'), 6),\n",
       " (('works', 'well', 'easy', 'install'), 6),\n",
       " (('easy', 'install', 'works', 'great'), 6),\n",
       " (('easy', 'install', 'looks', 'great'), 5),\n",
       " (('except', 'water', 'supply', 'line'), 5),\n",
       " (('new', 'water', 'supply', 'line'), 5),\n",
       " (('less', 'water', 'old', 'one'), 4),\n",
       " (('adjust', 'water', 'level', 'tank'), 4),\n",
       " (('well', 'uses', 'little', 'water'), 4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the data \n",
    "# n = int(input('Which one do you want to look at? (1-8)'))\n",
    "\n",
    "word_frequency = FreqDist(N_grams)\n",
    "\n",
    "# # Identify co-occurring trigrams\n",
    "# cooccurring_trigrams = []\n",
    "# for N_grams in word_frequency:\n",
    "#     if word_frequency[N_grams] > 1:\n",
    "#         cooccurring_trigrams.append(N_grams)\n",
    "\n",
    "# word_frequency = FreqDist(cooccurring_trigrams)        \n",
    "word_frequency.most_common(10)\n",
    "# word_frequency.plot(30,cumulative=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e52729",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "Latent Dirichlet Allocation (LDA), which is a popular unsupervised learning algorithm used for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aaf1bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.005*\"review collected part promotion\" + 0.001*\"works well easy install\" + 0.001*\"standard reliant piece gpf\" + 0.001*\"highly recommend review collected\" + 0.001*\"piece gpf single flush\" + 0.001*\"recommend review collected part\" + 0.001*\"american standard reliant piece\" + 0.001*\"collected part promotion really\" + 0.001*\"collected part promotion reliant\" + 0.001*\"collected part promotion replaced\"\n",
      "Topic 1: 0.001*\"bathroom replace old one\" + 0.001*\"well easy install perfect\" + 0.000*\"installed easy looks nice\" + 0.000*\"need except supply line\" + 0.000*\"easy install took hour\" + 0.000*\"good product better standard\" + 0.000*\"good easy install issues\" + 0.000*\"bolts recommend small medium\" + 0.000*\"wont lower might cool\" + 0.000*\"person replace old make\"\n",
      "Topic 2: 0.001*\"easy install works great\" + 0.001*\"reliant piece gpf single\" + 0.001*\"part promotion installed guest\" + 0.001*\"gpf single flush elongated\" + 0.001*\"single flush elongated white\" + 0.001*\"promotion installed guest bathroom\" + 0.000*\"height makes big difference\" + 0.000*\"great price great price\" + 0.000*\"high quality american standard\" + 0.000*\"need adjust water level\"\n",
      "Topic 3: 0.001*\"slow close seat included\" + 0.001*\"super easy install comes\" + 0.000*\"box everything need install\" + 0.000*\"tank one replaced swapped\" + 0.000*\"piece easy install missing\" + 0.000*\"get clogged american standard\" + 0.000*\"great first time leaks\" + 0.000*\"much harder would definitely\" + 0.000*\"tightening nuts connecting tank\" + 0.000*\"going blow away bells\"\n",
      "Topic 4: 0.001*\"collected part promotion installed\" + 0.001*\"easy install everything needed\" + 0.001*\"works perfectly would recommend\" + 0.000*\"much better old one\" + 0.000*\"put one half bath\" + 0.000*\"looks great works well\" + 0.000*\"uses little water flush\" + 0.000*\"easy install works fine\" + 0.000*\"good product easy install\" + 0.000*\"flush great product price\"\n"
     ]
    }
   ],
   "source": [
    "words = [' '.join(tr) for tr in N_grams]\n",
    "# Step 2: Create a dictionary of words and convert the text into a bag-of-words format\n",
    "dictionary = corpora.Dictionary([words])\n",
    "corpus = [dictionary.doc2bow([word]) for word in words]\n",
    "\n",
    "# Step 3: Apply LDA to the corpus to identify topics in the text\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n",
    "\n",
    "# Step 4: Print the topics and the top words associated with each topic\n",
    "for i, topic in lda_model.show_topics(formatted=True, num_topics=5, num_words=10):\n",
    "    print(\"Topic {}: {}\".format(i, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fcc4e",
   "metadata": {},
   "source": [
    "### Text Summarization\n",
    "#### In summary, while topic modeling aims to uncover the underlying themes and topics in a large corpus of text, text summarization aims to provide a condensed version of a longer text, capturing the essential information and key points.\n",
    "#### Two different approaches are used for Text Summarization\n",
    "1. Extractive Summarization: In Extractive Summarization, we identify essential phrases or sentences from the original text and extract only these phrases from the text. These extracted sentences would be the summary.\n",
    "2. Abstractive Summarization: We work on generating new sentences from the original text in the Abstractive Summarization approach. The abstractive method contrasts the approach described above, and the sentences generated through this approach might not even be present in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "760537cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))\n",
    "# words = word_tokenize(result_text_1)\n",
    "freqTable = dict()\n",
    "for word in token:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n",
    "\n",
    "text_03 = remove_stopwords(text_01)\n",
    "sentences = sent_tokenize(text_03)\n",
    "# sentences = token\n",
    "sentenceValue = dict()\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "                \n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "    \n",
    "average = int(sumValues / len(sentenceValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bb68faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Easy install. easy install. easy install. Easy install. easy install. Easy installation. little taller normal toilets issue, would highly recommend price easy install,instruction right on,quality product,after install looked amount water used looked like little,but worked great.They pretested.Will buy another purchased today - installation breeze, however could adjust fill valve leaking, luckily spare fluidmaster fill valve... far flushing good .... needed new somehow tank old one got crack water spilled everywhere work. Easy install. Easy install. Easy installation. Easy install. easy install. easy install. easy install. Easy install. Easy install. Easy installation. Easy install. easy install. easy install. Easy install. Easy install. Easy install. easy install. Easy install. Easy install. Easy install. easy install. Easy install. Easy install. easy install. Easy install. Easy install. Easy install. Easy installation. Easy install. Easy install. easy install. Easy installation. Easy install. Easy install. easy install. easy install. Easy install. Easy install. easy install.\n"
     ]
    }
   ],
   "source": [
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (6.0 * average)):\n",
    "        summary += \" \" + sentence\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d42ef7",
   "metadata": {},
   "source": [
    "#### New Methond on Text Summarization\n",
    "Compute a score for each sentence based on its importance to the overall meaning of the text. The score can be based on various criteria, such as word frequency, sentence length, or semantic similarity to other sentences in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3117e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_03 = remove_stopwords(text_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00afa6a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a good toilet.\n",
      "It's a little taller than normal toilets but not an issue, I would highly recommend this toilet for the price Very easy to install,instruction where right on,quality product,after install looked at the amount of water used looked like it was to little,but it worked great.They are all pretested.Will buy another purchased today - installation was a breeze, however could not adjust the fill valve because it was leaking, luckily i had a spare fluidmaster toilet fill valve... so far it is flushing good .... i needed a new toilet because somehow the tank in my old one got a crack in it and water spilled everywhere while i was at work.\n",
      "The toilet was fine but the toilet seat was cheap and I had to buy a new one Not hard at all to install.\n",
      "The only issue I have with this toilet is the bowl does not have a lot of water in it I’ve tried everything but it still has very little water after you flush Well, the height is very nice, and the look and flush - even the lid (plastic) is fine, but the plastic seat is most disappointing - so thin it bends when one sits down (we're not THAT heavy!)\n",
      "It's a toilet.\n",
      "Just had it installed not sure how it may work but looks nice in my bathroom.lol I love that this toilet is Inexpensive, works great, and is a comfortable height i like the chair hiegth of the toilet also the price is great for the quality I really like this toilet.\n",
      "Nice style, good height, great installation by Lowes Nice color and sits at a great height for getting up and down Not happy with low water level...but its a water saving thing...so all in all its a good toilet....I didnt like the plastic seat so I changed it out for the one you see in the picture : )) This toilet is a great value and looks and performs perfectly.\n",
      "Works perfectly I would recommend this product Toilet installation fairly easy and it efficient as far as water use quiet flush the toilet was easy to install I love my new toilet It’s easy to use and very comfortable Toilets were easy to install and work great I love it my kids treat the toilet as if it’s a new car.\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_string(text_01, Tokenizer(\"english\"))\n",
    "summarizer = LexRankSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count=8)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b50ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c12530b7",
   "metadata": {},
   "source": [
    "### Context Analysis\n",
    "#### Check out the context of words having highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2700820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ADJ: 7142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pos and lemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm = lemmatizer.lemmatize(text_03)\n",
    "pos_tag_1 = pos_tag(word_tokenize(lemm))\n",
    "# pos_tag_1\n",
    "\n",
    "### select Adjective or Noun \n",
    "result_adj_1 = []\n",
    "for token, tag in pos_tag_1:\n",
    "    if tag[0:1].lower() == \"j\":   ### j represents Adj. n represents noun\n",
    "        result_adj_1.append(token)\n",
    "print(f\"Total number of ADJ: {len(result_adj_1)}\\n\")\n",
    "# print(result_adj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e026cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most common Adjective. word appear in review is: [('great', 342), ('easy', 341), ('good', 274), ('old', 241), ('flush', 153), ('new', 149), ('little', 127), ('American', 110), ('install', 103), ('small', 98)]\n"
     ]
    }
   ],
   "source": [
    "# see each Adjective frequence\n",
    "ADJ_f_1 = FreqDist(result_adj_1)\n",
    "# ADJ_f_1\n",
    "print(f\"The top 10 most common Adjective. word appear in review is: {ADJ_f_1.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80c70052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of noun: 13977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pos and lemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm = lemmatizer.lemmatize(text_03)\n",
    "pos_tag_1 = pos_tag(word_tokenize(lemm))\n",
    "# pos_tag_1\n",
    "\n",
    "### select Adjective or Noun \n",
    "result_adj_1 = []\n",
    "for token, tag in pos_tag_1:\n",
    "    if tag[0:1].lower() == \"n\":   ### j represents Adj. n represents noun\n",
    "        result_adj_1.append(token)\n",
    "print(f\"Total number of noun: {len(result_adj_1)}\\n\")\n",
    "# print(result_adj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e343cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most common Noun. word appear in review is: [('water', 494), ('seat', 382), ('toilet', 357), ('install', 253), ('toilets', 232), ('flush', 214), ('tank', 197), ('bathroom', 188), ('price', 187), ('product', 162)]\n"
     ]
    }
   ],
   "source": [
    "# see each noun frequence\n",
    "noun_f_1 = FreqDist(result_adj_1)\n",
    "print(f\"The top 10 most common Noun. word appear in review is: {noun_f_1.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e051433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of verb: 6621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pos and lemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm = lemmatizer.lemmatize(text_03)\n",
    "pos_tag_1 = pos_tag(word_tokenize(lemm))\n",
    "# pos_tag_1\n",
    "\n",
    "### select Adjective or Noun \n",
    "result_adj_1 = []\n",
    "for token, tag in pos_tag_1:\n",
    "    if tag[0:1].lower() == \"v\":   ### j represents Adj. n represents noun\n",
    "        result_adj_1.append(token)\n",
    "print(f\"Total number of verb: {len(result_adj_1)}\\n\")\n",
    "# print(result_adj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b023a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most common Verb. word appear in review is: [('installed', 164), ('bought', 127), ('works', 126), ('replace', 122), ('get', 116), ('needed', 115), ('purchased', 99), ('replaced', 93), ('included', 87), ('flushing', 81)]\n"
     ]
    }
   ],
   "source": [
    "# see each noun frequence\n",
    "noun_f_1 = FreqDist(result_adj_1)\n",
    "print(f\"The top 10 most common Verb. word appear in review is: {noun_f_1.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336dab77",
   "metadata": {},
   "source": [
    "#### New Method to Get Context of Key Words\n",
    "using original text of reviews and locate the full sentence, then sample them to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04c7df14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lxf12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seat is not the best so that kept us from giving it a 5 star rating.\n",
      "But I had a new toilet seat to install.\n",
      "Love the 17.5 height from floor to seat and the water efficient flushing action.\n",
      "The seat is flimsy but the rest of it is constructed well.\n",
      "The toilet seat is a little flimsy though.\n",
      "I went back to Home Depot and the manager let me get a different seat that was made better.\n",
      "But the seat is very flimsy.\n",
      "My only complaint has to do with a toilet seat.\n",
      "I love the slow close seat.\n",
      "Kind of a strange feel, but easily remedied with a new seat, if it bothers you enough.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the Punkt tokenizer\n",
    "\n",
    "# result_text_1 = datalist[n-1]['Review'].to_string(index=False)\n",
    "# result_text_1 = text[n-1]\n",
    "keyword = \"seat\"\n",
    "max_sentence_length = 150\n",
    "num_samples = 10\n",
    "\n",
    "sentences = nltk.sent_tokenize(text_01)\n",
    "matching_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    if keyword in sentence:\n",
    "        if len(sentence) <= max_sentence_length:\n",
    "            matching_sentences.append(sentence)\n",
    "\n",
    "if len(matching_sentences) >= num_samples:\n",
    "    samples = random.sample(matching_sentences, num_samples)\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "else:\n",
    "    print(\"Not enough matching sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b6ca1",
   "metadata": {},
   "source": [
    "locate the fixed length context, then sample them to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ade044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                   \n",
      "Says slow close seat and it definitely isn’t, should b corrected                                                        \n",
      "   \n",
      "American Standard has a winner in this little beauty. Easy to install (did it myself except for seating the toilet on the wax ring, then had my husband do that). Perfect height, all the accessories to\n",
      "e side. I like that better. Easier to spray with disinfectant when cleaning. It comes with a toilet seat that goes slow as it auto closes. But you do have to sort of start the motion or it won't lower by \n",
      "ilets. Sits taller than standard ones and uses less water. Never an issue flushing. I would say the seat isnt as comfortable as my last one                                                                 \n",
      "t and the elongated toilet. The only thing I do not like about the toilet is the cheap hard plastic seat that is on it. I feel that American Standard should replace the seat with a more confortable seat t\n",
      "k and I'm pleased with them. They have, however, continued to ship a completely lame flimsy plastic seat so we use a heavier duty after market seat instead. But given this unit is $99 having to buy a bett\n",
      "                                        \n",
      "Price could have been better considering the cheap plastic seat it comes with, but overall, does what its supposed to, easy installation.                          \n",
      "le seat for $12. I replaced the seat that came with my toilet. Wish the toilet came with the wooden seat from getgo.                                                                                        \n",
      "t flushes quietly, fills quickly and flushes everything on the first flush. I will be replacing the seat, then it should be perfect.                                                                        \n",
      "o not find them noisy at all. In fact our old toilets were much louder than these when filling. The seat provided is, in our opinion, just fine. It does not move and is just fine. Again, put on and tighte\n"
     ]
    }
   ],
   "source": [
    "# result_text_1 = datalist[n-1]['Review'].to_string(index=False)\n",
    "# result_text_1 = text[n-1]\n",
    "keyword = \"seat\"\n",
    "context_length = 100\n",
    "num_samples = 10\n",
    "\n",
    "pattern = re.compile(re.escape(keyword))\n",
    "\n",
    "matches = [(match.start(), match.end()) for match in pattern.finditer(text_01)]\n",
    "\n",
    "matching_contexts = []\n",
    "for start, end in matches:\n",
    "    context_start = max(0, start - context_length)\n",
    "    context_end = min(len(text_01), end + context_length)\n",
    "    context = text_01[context_start:end] + text_01[end:context_end]\n",
    "    matching_contexts.append(context)\n",
    "\n",
    "if len(matching_contexts) >= num_samples:\n",
    "    samples = random.sample(matching_contexts, num_samples)\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "else:\n",
    "    print(\"Not enough matching contexts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96950987",
   "metadata": {},
   "source": [
    "#### Text Summarization on the Matching sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a1e34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_sentences = ' '.join(matching_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bc43ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(matching_sentences)\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n",
    "\n",
    "sentences = sent_tokenize(matching_sentences)\n",
    "sentenceValue = dict()\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "                \n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "    \n",
    "average = int(sumValues / len(sentenceValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efbcf554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The toilet seat is cheap but fortunately the old one, purchased new last year, fits well. Also, the toilet seat is rather cheaply made, but I bought a nickel brushed hinge toilet seat that is slow close and that fixed that problem. We too replaced the plastic seat with a $10 wooden seat, but we really like the toilet. The toilet seat is a little flimsy but, I do like the way it closes slowly and quietly. The only (slight) downside is the plastic toilet seat that came with it - it is not real sturdy, but is adequate. As many of the other reviewers noted, the seat and lid of this toilet are flimsy and paper-thin plastic. The cheap, white seat that's included enables A.S. to keep the price of the toilet down -- and surely, this toilet is a bargain. From my perspective, at least, I'd rather they kept the price down than provide me with a better toilet seat that I wouldn't use. I didn't use the plastic seat that comes with the toilet, like the Church seats Lowes sells much better.\n"
     ]
    }
   ],
   "source": [
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.28 * average)):\n",
    "        summary += \" \" + sentence\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2c291741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seat is very uncomfortable however so I will be buying a new soft close seat that is hopefully more comfortable to sit on..\n",
      "I used a seat I had just bought for our old toilet as the one that comes in the box is a standard low quality type.\n",
      "The only thing I did not like was the cheap seat and lid that came with it.\n",
      "The only thing I do not like about the toilet is the cheap hard plastic seat that is on it.\n",
      "I really like this toilet, except that the seat is a little flimsy.\n",
      "I replaced the seat that came with my toilet.\n",
      "And I like the seat that comes with it.\n",
      "But the seat is very flimsy.\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_string(matching_sentences, Tokenizer(\"english\"))\n",
    "summarizer = LexRankSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count=8)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7c198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f370ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
